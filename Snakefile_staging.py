
rule qc_atropos:
    """
    Does adapter trimming and read QC with Atropos
    """
    input:
        forward = raw_dir + "{sample}/combined_reads/{sample}.R1.fastq.gz",
        reverse = raw_dir + "{sample}/combined_reads/{sample}.R2.fastq.gz"
    output:
        forward = qc_dir + "{sample}/{trimmer}_trimmed/{sample}.trimmed.R1.fastq.gz",
        reverse = qc_dir + "{sample}/{trimmer}_trimmed/{sample}.trimmed.R2.fastq.gz"
    threads:
        12
    conda:
        "envs/qp-shotgun.yaml"
    params:
        atropos = config['params']['atropos']
    log:
        qc_dir + "logs/qc_atropos.sample=[{sample}].log"
    benchmark:
        "benchmarks/qc/qc_atropos.sample=[{sample}].txt"
    run:
        with tempfile.TemporaryDirectory(dir=find_local_scratch(TMP_DIR_ROOT)) as temp_dir:
            f_fp = os.path.basename(output.forward)
            r_fp = os.path.basename(output.reverse)
            shell("""
                    atropos --threads {threads} {params.atropos} --report-file {log} --report-formats txt -o {temp_dir}/{f_fp} -p {temp_dir}/{r_fp} -pe1 {input.forward} -pe2 {input.reverse}

                    scp {temp_dir}/{f_fp} {output.forward}
                    scp {temp_dir}/{r_fp} {output.reverse}
                  """)

rule qc_filter:
    """
    Performs host read filtering on paired end data using Bowtie and Samtools/
    BEDtools. Takes the four output files generated by Trimmomatic. 

    Also requires an indexed reference (path specified in config). 

    First, uses Bowtie output piped through Samtools to only retain read pairs
    that are never mapped (either concordantly or just singly) to the indexed
    reference genome. Fastqs from this are gzipped into matched forward and 
    reverse pairs. 

    Unpaired forward and reverse reads are simply run through Bowtie and
    non-mapping gzipped reads output.

    All piped output first written to localscratch to avoid tying up filesystem.
    """
    input:
        forward = qc_dir + "{sample}/%s_trimmed/{sample}.trimmed.R1.fastq.gz" % trimmer,
        reverse = qc_dir + "{sample}/%s_trimmed/{sample}.trimmed.R2.fastq.gz" % trimmer
    output:
        forward = qc_dir + "{sample}/filtered/{sample}.R1.trimmed.filtered.fastq.gz",
        reverse = qc_dir + "{sample}/filtered/{sample}.R2.trimmed.filtered.fastq.gz"
    params:
        filter_db = lambda wildcards: config['samples'][wildcards.sample]['filter_db']
    threads:
        12
    log:
        bowtie = qc_dir + "logs/qc_filter.bowtie.sample=[{sample}].log",
        other = qc_dir + "logs/qc_filter.other.sample=[{sample}].log"
    benchmark:
         "benchmarks/qc/qc_filter.sample=[{sample}].txt"
    run:
        if params.filter_db is None:
            f_fp = os.path.abspath(input.forward)
            r_fp = os.path.abspath(input.reverse)
            shell("""
                    ln -s {f_fp} {output.forward}
                    ln -s {r_fp} {output.reverse}

                    echo 'No DB provided; sample not filtered.' > {log.bowtie}
                    echo 'No DB provided; sample not filtered.' > {log.other}
                  """)
        else:
            with tempfile.TemporaryDirectory(dir=find_local_scratch(TMP_DIR_ROOT)) as temp_dir:
                shell("""
                      bowtie2 -p {threads} -x {params.filter_db} --very-sensitive -1 {input.forward} -2 {input.reverse} 2> {log.bowtie}| \
                      samtools view -f 12 -F 256 2> {log.other}| \
                      samtools sort -T {temp_dir} -@ {threads} -n 2> {log.other} | \
                      samtools view -bS 2> {log.other} | \
                      bedtools bamtofastq -i - -fq {temp_dir}/{wildcards.sample}.R1.trimmed.filtered.fastq -fq2 {temp_dir}/{wildcards.sample}.R2.trimmed.filtered.fastq 2> {log.other}

                      pigz -c {temp_dir}/{wildcards.sample}.R1.trimmed.filtered.fastq > {temp_dir}/{wildcards.sample}.R1.trimmed.filtered.fastq.gz
                      pigz -c {temp_dir}/{wildcards.sample}.R2.trimmed.filtered.fastq > {temp_dir}/{wildcards.sample}.R2.trimmed.filtered.fastq.gz

                      scp {temp_dir}/{wildcards.sample}.R1.trimmed.filtered.fastq.gz {output.forward}
                      scp {temp_dir}/{wildcards.sample}.R2.trimmed.filtered.fastq.gz {output.reverse} 
                      """)


rule function_humann2:
    """
    Runs HUMAnN2 pipeline using general defaults.

    Other HUMAnN2 parameters can be specified as a quoted string in 
    PARAMS: HUMANN2: OTHER. 

    Going to do just R1 reads for now. Because of how I've split PE vs SE
    processing and naming, still will need to make a separate rule for PE. 
    """
    input:
        forward = qc_dir + "{sample}/filtered/{sample}.R1.trimmed.filtered.fastq.gz",
        reverse = qc_dir + "{sample}/filtered/{sample}.R2.trimmed.filtered.fastq.gz",
        metaphlan_in = tax_dir + "metaphlan2/joined_taxonomic_profile_max.tsv"
    output:
        genefamilies = func_dir + "{sample}/humann2/{sample}_genefamilies.biom",
        pathcoverage = func_dir + "{sample}/humann2/{sample}_pathcoverage.biom",
        pathabundance = func_dir + "{sample}/humann2/{sample}_pathabundance.biom"
    params:
        metaphlan_dir = config['params']['humann2']["metaphlan_dir"],
        humann2_nt_db = config['params']['humann2']["humann2_nt_db"],
        humann2_aa_db = config['params']['humann2']["humann2_aa_db"],
        humann2_env = config['humann2_env'],
        other = config['params']['humann2']['other']
    threads:
        8
    log:
        func_dir + "logs/function_humann2_{sample}.log"
    benchmark:
        "benchmarks/function/function_humann2_{sample}.json"
    run:
        with tempfile.TemporaryDirectory(dir=TMP_DIR_ROOT) as temp_dir:
            shell("""
                  set +u; {params.humann2_env}; set -u

                  zcat {input.forward} {input.reverse} > {temp_dir}/input.fastq

                  humann2 --input {temp_dir}/input.fastq \
                  --output {temp_dir}/{wildcards.sample} \
                  --output-basename {wildcards.sample} \
                  --nucleotide-database {params.humann2_nt_db} \
                  --protein-database {params.humann2_aa_db} \
                  --taxonomic-profile {input.metaphlan_in} \
                  --metaphlan {params.metaphlan_dir} \
                  --o-log {log} \
                  --threads {threads} \
                  --output-format biom {params.other} 2> {log} 1>&2


                  scp {temp_dir}/{wildcards.sample}/{wildcards.sample}_genefamilies.biom {output.genefamilies}
                  scp {temp_dir}/{wildcards.sample}/{wildcards.sample}_pathcoverage.biom {output.pathcoverage}
                  scp {temp_dir}/{wildcards.sample}/{wildcards.sample}_pathabundance.biom {output.pathabundance}
                  """)


rule function_humann2_renorm_tables:
    """
    Renormalizes HUMAnN2 per-sample tables, per recommendation in the HUMAnN2
    website. 

    Counts-per-million (cpm) or Relative Abundance (Relabund) can be specified
    as a list in the PARAMS: HUMANN2: NORMS variable in the config file.
    """
    input:
        genefamilies = func_dir + "{sample}/humann2/{sample}_genefamilies.biom",
        pathcoverage = func_dir + "{sample}/humann2/{sample}_pathcoverage.biom",
        pathabundance = func_dir + "{sample}/humann2/{sample}_pathabundance.biom"
    output:
        genefamilies = func_dir + "{sample}/humann2/{sample}_genefamilies_{norm}.biom",
        pathcoverage = func_dir + "{sample}/humann2/{sample}_pathcoverage_{norm}.biom",
        pathabundance = func_dir + "{sample}/humann2/{sample}_pathabundance_{norm}.biom"
    threads:
        1
    params:
        humann2_env = config['humann2_env']
    log:
        func_dir + "logs/function_humann2_renorm_tables_{sample}_{norm}.log"
    benchmark:
        "benchmarks/function/function_humann2_renorm_tables_{sample}_{norm}.json"
    run:
        shell("""
              set +u; {params.humann2_env}; set -u

              humann2_renorm_table --input {input.genefamilies} \
              --output {output.genefamilies} \
              --units {wildcards.norm} 2> {log} 1>&2

              humann2_renorm_table --input {input.pathcoverage} \
              --output {output.pathcoverage} \
              --units {wildcards.norm} 2>> {log} 1>&2

              humann2_renorm_table --input {input.pathabundance} \
              --output {output.pathabundance} \
              --units {wildcards.norm} 2>> {log} 1>&2
              """)


rule function_humann2_combine_tables:
    """
    Combines the per-sample normalized tables into a single run-wide table. 

    Because HUMAnN2 takes a directory as input, first copies all the individual
    tables generated in this run to a temp directory and runs on that.
    """
    input:
        lambda wildcards: expand(func_dir + "{sample}/humann2/{sample}_genefamilies_{norm}.biom",
               sample=samples, norm=wildcards.norm),
        lambda wildcards: expand(func_dir + "{sample}/humann2/{sample}_pathcoverage_{norm}.biom",
               sample=samples, norm=wildcards.norm),
        lambda wildcards: expand(func_dir + "{sample}/humann2/{sample}_pathabundance_{norm}.biom",
               sample=samples, norm=wildcards.norm)
    output:
        genefamilies = func_dir + "humann2/combined_genefamilies_{norm}_all.biom",
        pathcoverage = func_dir + "humann2/combined_pathcoverage_{norm}_all.biom",
        pathabundance = func_dir + "humann2/combined_pathabundance_{norm}_all.biom"
    log:
        func_dir + "logs/function_humann2_combine_tables_{norm}.log"
    params:
        humann2_env = config['humann2_env']
    benchmark:
        "benchmarks/function/function_humann2_combine_tables_{norm}.json"
    run:
        with tempfile.TemporaryDirectory(dir=func_dir + "humann2") as temp_dir:
            for file in input:
                shell("cp {0} {1}/.".format(file, temp_dir))
            shell("""
                  set +u; {params.humann2_env}; set -u

                  humann2_join_tables --input {temp_dir} \
                  --output {output.genefamilies} \
                  --file_name genefamilies 2> {log} 1>&2

                  humann2_join_tables --input {temp_dir} \
                  --output {output.pathcoverage} \
                  --file_name pathcoverage 2>> {log} 1>&2

                  humann2_join_tables --input {temp_dir} \
                  --output {output.pathabundance} \
                  --file_name pathabundance 2>> {log} 1>&2

                  """)

rule function_humann2_remove_unmapped:
    """
    By default, HUMAnN2 includes the un-annoated reads (either unmapped in the
    first step of the pipeline or not matched in the translated alignment step)
    in the output files. In my experience, this causes relatively small
    differences in run quality (e.g. different read lengths) to have huge
    effects on the evaluated outcome, as the overall proportion of unmatched
    reads varies by run, and the compositionality of the data then causes large
    fluctuations in the count estimates of the annotated genes and pathways.

    To remove this problem, this rule renormalizes the combined tables after
    extracting unmatched read categories.
    """
    input:
        genefamilies = func_dir + "humann2/combined_genefamilies_{norm}_all.biom",
        pathcoverage = func_dir + "humann2/combined_pathcoverage_{norm}_all.biom",
        pathabundance = func_dir + "humann2/combined_pathabundance_{norm}_all.biom"
    output:
        genefamilies = func_dir + "humann2/combined_genefamilies_{norm}_mapped.biom",
        pathcoverage = func_dir + "humann2/combined_pathcoverage_{norm}_mapped.biom",
        pathabundance = func_dir + "humann2/combined_pathabundance_{norm}_mapped.biom"
    threads:
        1
    params:
        humann2_env = config['humann2_env']
    log:
        func_dir + "logs/function_humann2_remove_unmapped_{norm}.log"
    benchmark:
        "benchmarks/function/function_humann2_remove_unmapped_{norm}.json"
    run:
        shell("""
              set +u; {params.humann2_env}; set -u

              humann2_renorm_table --input {input.genefamilies} \
              --output {output.genefamilies} \
              --units {wildcards.norm} -s n 2> {log} 1>&2

              humann2_renorm_table --input {input.pathcoverage} \
              --output {output.pathcoverage} \
              --units {wildcards.norm} -s n 2>> {log} 1>&2

              humann2_renorm_table --input {input.pathabundance} \
              --output {output.pathabundance} \
              --units {wildcards.norm} -s n 2>> {log} 1>&2
              """)


rule function_humann2_split_stratified_tables:
    """
    Splits the grouped tables into separate grouped taxonomy-stratified and un-
    stratified tables for downstream analysis. Does this for both the combined
    tables including unmatched reads (*_all) and those excluding unmatched
    reads (*_mapped).

    The un-stratified tables should then be directly useful for downstream
    analysis in e.g. beta diversity. 
    """
    input:
        genefamilies = func_dir + "humann2/combined_genefamilies_{norm}_{mapped}.biom",
        pathcoverage = func_dir + "humann2/combined_pathcoverage_{norm}_{mapped}.biom",
        pathabundance = func_dir + "humann2/combined_pathabundance_{norm}_{mapped}.biom"
    output:
        genefamilies = func_dir + "humann2/stratified/combined_genefamilies_{norm}_{mapped}_stratified.biom",
        pathcoverage = func_dir + "humann2/stratified/combined_pathcoverage_{norm}_{mapped}_stratified.biom",
        pathabundance = func_dir + "humann2/stratified/combined_pathabundance_{norm}_{mapped}_stratified.biom",
        genefamilies_unstrat = func_dir + "humann2/stratified/combined_genefamilies_{norm}_{mapped}_unstratified.biom",
        pathcoverage_unstrat = func_dir + "humann2/stratified/combined_pathcoverage_{norm}_{mapped}_unstratified.biom",
        pathabundance_unstrat = func_dir + "humann2/stratified/combined_pathabundance_{norm}_{mapped}_unstratified.biom"
    threads:
        1
    params:
        humann2_env = config['humann2_env']
    log:
        func_dir + "logs/function_humann2_split_stratified_tables_{norm}_{mapped}.log"
    benchmark:
        "benchmarks/function/function_humann2_split_stratified_tables_{norm}_{mapped}.json"
    run:
        out_dir = os.path.dirname(output[0])
        shell("""
              set +u; {params.humann2_env}; set -u

              humann2_split_stratified_table --input {input.genefamilies} \
              --output {out_dir} 2> {log} 1>&2

              humann2_split_stratified_table --input {input.pathcoverage} \
              --output {out_dir} 2>> {log} 1>&2

              humann2_split_stratified_table --input {input.pathabundance} \
              --output {out_dir} 2>> {log} 1>&2
              """)
